{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a4e076",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import shutil\n",
    "import datetime\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from skimage.io import imread\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\n",
    "from scipy.stats import pearsonr\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "from utils.logging import *\n",
    "from data.datasets import PatchPathDataset\n",
    "from data.process import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56c6c8c",
   "metadata": {},
   "source": [
    "### Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17c32bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = pd.Series({\n",
    "    'checkpoint':'checkpoint/',\n",
    "    'version': '1.0',\n",
    "    'image_dir': 'Data/',\n",
    "    'patch_label': 'Metadata/PatchLabels.csv',\n",
    "    'predicting_var': 'response',\n",
    "    'cohort': 'Cohort1',\n",
    "    'magnification': '10X',\n",
    "    'num_classes': 1,\n",
    "    'prediction': 'binary classification', # ['regression', 'binary classification', classification']\n",
    "    'upsample': True,\n",
    "    'train_val_split': 0.7,\n",
    "    'random_crop': False,\n",
    "    'features': 2048,\n",
    "    'loss': 'bce',\n",
    "    'epochs': 20, \n",
    "    'start_epoch': 0,\n",
    "    'lr': 0.1,\n",
    "    'momentum': 0.9,\n",
    "    'weight_decay': 1e-4,\n",
    "    'batch_size': 256,\n",
    "    'workers': 4,\n",
    "    'evaluate': False,\n",
    "    'seed': 0,\n",
    "    'gpu': 0,\n",
    "    'log_interval': 50,\n",
    "    'log': False\n",
    "})\n",
    "\n",
    "if args.log:\n",
    "    sub_dir = 'tensorboard'\n",
    "    tensorboard_dir = f'logs/{sub_dir}/BaselineResNet{args.version}/' \n",
    "    if not os.path.exists(tensorboard_dir):\n",
    "        os.makedirs(tensorboard_dir)\n",
    "    \n",
    "    current_time = str(datetime.datetime.now().strftime(\"%d%m%Y-%H:%M:%S\"))\n",
    "    train_log_dir = tensorboard_dir + 'train/' + current_time\n",
    "    val_log_dir = tensorboard_dir + 'val/' + current_time\n",
    "    train_summary_writer = SummaryWriter(log_dir=train_log_dir)\n",
    "    val_summary_writer = SummaryWriter(log_dir=val_log_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850ee12e",
   "metadata": {},
   "source": [
    "### Metrics and save functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed24f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(output, target):\n",
    "    with torch.no_grad():\n",
    "        sig = nn.Sigmoid()\n",
    "        if args.prediction == 'binary classification':\n",
    "            prob_output = sig(output)\n",
    "            first_acc = roc_auc_score(target.cpu(), prob_output.cpu(), multi_class='ovr', average='weighted')\n",
    "            second_acc = accuracy_score(torch.round(prob_output).cpu(), target.cpu())\n",
    "        elif args.prediction == 'classification':\n",
    "            first_acc = roc_auc_score(target.cpu(), output.cpu(), multi_class='ovo', average='macro')\n",
    "            second_acc = accuracy_score(torch.argmax(output).cpu(), target.cpu())\n",
    "        elif args.prediction == 'regression':\n",
    "            mae_loss = nn.L1Loss()\n",
    "            first_acc = mae_loss(output.squeeze(), target)\n",
    "            second_acc, _ = pearsonr(target.cpu(), output.squeeze().cpu())\n",
    "        else:\n",
    "            raise IOError(f'Metrics not defined for prediction format: {args.prediction}')\n",
    "        return first_acc, second_acc\n",
    "    \n",
    "def save_checkpoint(state, is_best, epoch, args, filename='checkpoint.pth.tar'):\n",
    "    save_dir = os.path.join(args.checkpoint, f'BaselineResNet{args.version}')\n",
    "    epoch_dir = os.path.join(save_dir, f'epoch_{epoch}')\n",
    "    if not os.path.exists(epoch_dir):\n",
    "        os.makedirs(epoch_dir)\n",
    "        print(f'Created new directory for saving models at {epoch_dir}')\n",
    "    save_path = os.path.join(epoch_dir, filename)\n",
    "    torch.save(state, save_path)\n",
    "    best_path = os.path.join(save_dir, 'model_best.pth.tar')\n",
    "    if is_best:\n",
    "        shutil.copyfile(save_path, best_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cc8700",
   "metadata": {},
   "source": [
    "### Train and loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4aa2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch, args, first_metric, second_metric):\n",
    "    batch_time = AverageMeter('Time', ':4.3f')\n",
    "    data_time = AverageMeter('Data', ':4.3f')\n",
    "    losses = AverageMeter('Loss', ':4.2f')\n",
    "    metric = AverageMeter(first_metric, ':4.2f')\n",
    "    metric2 = AverageMeter(second_metric, ':4.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(train_loader),\n",
    "        [batch_time, data_time, losses, metric, metric2],\n",
    "        prefix=\"Epoch: [{}]\".format(epoch),\n",
    "        summary_prefix='Training:')\n",
    "    \n",
    "    sig = nn.Sigmoid()\n",
    "    \n",
    "    outputs = []\n",
    "    targets = []\n",
    "\n",
    "    model.train()\n",
    "    end = time.time()\n",
    "    train_size = len(train_loader)\n",
    "    \n",
    "    for i, (images, target, _) in enumerate(train_loader):\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        if (args.gpu is not None) and (torch.cuda.is_available()):\n",
    "            images = images.cuda(args.gpu, non_blocking=True)\n",
    "            target = target.cuda(args.gpu, non_blocking=True)\n",
    "\n",
    "        output = model(images)\n",
    "        if args.loss == 'mse':\n",
    "            output = sig(output) # scale between 0 and 1\n",
    "            output = output.type(torch.FloatTensor)\n",
    "            target = target.type(torch.FloatTensor)\n",
    "        loss = criterion(output.squeeze(), target)\n",
    "        \n",
    "        losses.update(loss.item(), images.size(0))\n",
    "        outputs.extend(output)\n",
    "        targets.extend(target)\n",
    "                \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % args.log_interval == 0:\n",
    "            progress.display(i)    \n",
    "        \n",
    "        del i, images, target\n",
    "    \n",
    "    outputs = torch.stack(outputs, dim=0)\n",
    "    targets = torch.stack(targets, dim=0)\n",
    "\n",
    "    acc1, acc2 = metrics(outputs, targets)\n",
    "    metric.update(acc1, train_size)\n",
    "    metric2.update(acc2, train_size)\n",
    "    \n",
    "    del outputs, targets\n",
    "    \n",
    "    progress.display_summary()\n",
    "    if args.log:\n",
    "        train_summary_writer.add_scalar(f'Loss/{args.loss}', losses.avg, epoch)\n",
    "        train_summary_writer.add_scalar(first_metric, metric.avg, epoch)\n",
    "        train_summary_writer.add_scalar(second_metric, metric2.avg, epoch)\n",
    "\n",
    "\n",
    "def validate(val_loader, model, criterion, epoch, args, first_metric, second_metric):\n",
    "    batch_time = AverageMeter('Time', ':4.3f', Summary.NONE)\n",
    "    losses = AverageMeter('Loss', ':4.2f', Summary.NONE)\n",
    "    metric1 = AverageMeter(first_metric, ':4.2f', Summary.AVERAGE)\n",
    "    metric2 = AverageMeter(second_metric, ':4.2f', Summary.AVERAGE)\n",
    "    progress = ProgressMeter(\n",
    "        len(val_loader),\n",
    "        [batch_time, losses, metric1, metric2],\n",
    "        prefix='Validation: ',\n",
    "        summary_prefix='Validation: ')\n",
    "    \n",
    "    outputs = []\n",
    "    targets = []\n",
    "\n",
    "    model.eval()\n",
    "    val_size = len(val_loader)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        sig = nn.Sigmoid()\n",
    "        end = time.time()\n",
    "        for i, (images, target, _) in enumerate(val_loader):\n",
    "            if (args.gpu is not None) and (torch.cuda.is_available()):\n",
    "                images = images.cuda(args.gpu, non_blocking=True)\n",
    "                target = target.cuda(args.gpu, non_blocking=True)\n",
    "\n",
    "            output = model(images)\n",
    "            if args.loss == 'mse':\n",
    "                output = sig(output) # scale between 0 and 1\n",
    "                output = output.type(torch.FloatTensor)\n",
    "                target = target.type(torch.FloatTensor)\n",
    "            loss = criterion(output.squeeze(), target)\n",
    "            \n",
    "            losses.update(loss.item(), images.size(0))\n",
    "\n",
    "            outputs.extend(output)\n",
    "            targets.extend(target)\n",
    "\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % args.log_interval == 0:\n",
    "                progress.display(i)\n",
    "            del i, images, target\n",
    "        \n",
    "    outputs = torch.stack(outputs, dim=0)\n",
    "    targets = torch.stack(targets, dim=0)\n",
    "    \n",
    "    acc1, acc2 = metrics(outputs, targets)\n",
    "    metric1.update(acc1, val_size)\n",
    "    metric2.update(acc2, val_size)\n",
    "        \n",
    "    progress.display_summary()\n",
    "    \n",
    "    if args.log:\n",
    "        val_summary_writer.add_scalar(f'Loss/{args.loss}',  losses.avg, epoch)\n",
    "        val_summary_writer.add_scalar(first_metric,  metric1.avg, epoch)\n",
    "        val_summary_writer.add_scalar(second_metric,  metric2.avg, epoch)\n",
    "    \n",
    "    return metric1.avg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279b072a",
   "metadata": {},
   "source": [
    "# Train ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfda9d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_worker(gpu, args):\n",
    "    global best_acc1\n",
    "    args.gpu = gpu\n",
    "\n",
    "    print('Using ResNet pre-trained on ImageNet')\n",
    "    model = torchvision.models.resnet50(pretrained=True)\n",
    "    model.fc = nn.Linear(in_features=args.features, out_features=args.num_classes, bias=True)\n",
    "\n",
    "    if not torch.cuda.is_available():\n",
    "        print('using CPU, this will be slow')\n",
    "    elif args.gpu is not None:\n",
    "        print(\"Use GPU: {} for training\".format(args.gpu))\n",
    "        torch.cuda.set_device(args.gpu)\n",
    "        model = model.cuda(args.gpu)\n",
    "        \n",
    "    if args.prediction in ['classification', 'binary classification']:\n",
    "        metric = 'AUC'\n",
    "        second_metric = 'Accuracy'\n",
    "    elif args.prediction == 'regression':\n",
    "        metric = 'Pearson correlation'\n",
    "        second_metric = 'MAE'\n",
    "    else:\n",
    "        raise IOError(f'Metrics not defined for prediction format: {args.prediction}')\n",
    "\n",
    "    # define loss function (criterion), optimizer, and learning rate scheduler\n",
    "    if args.loss == 'ce':  # use in classification\n",
    "        criterion = nn.CrossEntropyLoss().cuda(args.gpu)\n",
    "    elif args.loss == 'mse':  # use in cts case (on either normalized or standardized or raw data)\n",
    "        criterion = nn.MSELoss().cuda(args.gpu)\n",
    "    elif args.loss == 'bce':  # use in binary case\n",
    "        criterion = nn.BCEWithLogitsLoss().cuda(args.gpu)  # bce with sigmoid, so don't have to add to model\n",
    "\n",
    "    optimizer = torch.optim.SGD(model.parameters(), args.lr,\n",
    "                                momentum=args.momentum,\n",
    "                                weight_decay=args.weight_decay)\n",
    "\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    scheduler = StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "    # Load data\n",
    "    patch_labels = pd.read_csv(args.patch_label, index_col=0)\n",
    "    patch_labels = patch_labels[patch_labels.magnification == args.magnification]\n",
    "    patch_labels = patch_labels.dropna(subset=[args.predicting_var])\n",
    "    \n",
    "    train_patch_labels, val_patch_labels, val_cases, _ = split_train_val(patch_labels, args.cohort, \n",
    "                                                                         args.train_val_split, args.seed, \n",
    "                                                                         args.prediction, args.predicting_var,\n",
    "                                                                         args.upsample)\n",
    "    \n",
    "    full_transforms, lim_transforms = image_transforms(args.random_crop)\n",
    "\n",
    "    train_dataset = PatchPathDataset(patch_labels=train_patch_labels, image_folder=args.image_dir,\n",
    "                                     predicting_var=args.predicting_var, transform=full_transforms)\n",
    "\n",
    "    val_dataset = PatchPathDataset(patch_labels=val_patch_labels, image_folder=args.image_dir,\n",
    "                                   predicting_var=args.predicting_var, transform=lim_transforms)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True,\n",
    "                                               num_workers=args.workers, pin_memory=True, sampler=None)\n",
    "\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=args.batch_size, shuffle=False,\n",
    "                                             num_workers=args.workers, pin_memory=True)\n",
    "    \n",
    "    if args.log:\n",
    "        images, labels = next(iter(train_loader))\n",
    "        grid = torchvision.utils.make_grid(images, nrow=16)\n",
    "        train_summary_writer.add_image(f'Input images/v{args.version}', grid, 0)\n",
    "        train_summary_writer.add_graph(model, images.cuda(args.gpu))\n",
    "    \n",
    "        train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True,\n",
    "                                                   num_workers=args.workers, pin_memory=True, sampler=None)\n",
    "\n",
    "    if args.evaluate:\n",
    "        validate(val_loader, model, criterion, args, metric, second_metric)\n",
    "        return\n",
    "    \n",
    "    best_epoch = -1\n",
    "    for epoch in range(args.start_epoch, args.epochs):\n",
    "\n",
    "        # train for one epoch\n",
    "        train(train_loader, model, criterion, optimizer, epoch, args, metric, second_metric)\n",
    "\n",
    "        # evaluate on validation set\n",
    "        acc1 = validate(val_loader, model, criterion, epoch, args, metric, second_metric)\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        # remember best acc@1 and save checkpoint\n",
    "        if metric == 'AUC' or 'Pearson correlation':\n",
    "            is_best = acc1 > best_acc1 # ONLY FOR positive metrics!\n",
    "            best_acc1 = max(acc1, best_acc1)\n",
    "        elif metric == 'MAE':\n",
    "            is_best = acc1 < best_acc1\n",
    "            best_acc1 = min(acc1, best_acc1)\n",
    "        else:\n",
    "            raise IOError(f'best metric scenario not defined for metric {metric}')\n",
    "        \n",
    "        if is_best:\n",
    "            best_epoch = epoch\n",
    "\n",
    "        save_checkpoint({\n",
    "            'epoch': epoch,\n",
    "            'arch': 'resnet50',\n",
    "            'state_dict': model.state_dict(),\n",
    "            'best_metric': best_acc1,\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'scheduler': scheduler.state_dict(),\n",
    "            'val_cases': val_cases\n",
    "        }, is_best, epoch, args)\n",
    "        \n",
    "    if args.log:\n",
    "        metric_dict = {f'Best/{metric}': best_acc1, 'Best/Epoch': best_epoch}\n",
    "        val_summary_writer.add_hparams(hparam_dict=args.to_dict(), metric_dict=metric_dict)\n",
    "    \n",
    "        train_summary_writer.close()\n",
    "        #val_summary_writer.close()\n",
    "    \n",
    "    del model\n",
    "    \n",
    "    return val_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9823a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc1 = 0\n",
    "\n",
    "def main():\n",
    "\n",
    "    if args.seed is not None:\n",
    "        random.seed(args.seed)\n",
    "        torch.manual_seed(args.seed)\n",
    "        cudnn.deterministic = True\n",
    "        warnings.warn('You have chosen to seed training. '\n",
    "                      'This will turn on the CUDNN deterministic setting, '\n",
    "                      'which can slow down your training considerably! '\n",
    "                      'You may see unexpected behavior when restarting '\n",
    "                      'from checkpoints.')\n",
    "\n",
    "    if args.gpu is not None:\n",
    "        warnings.warn('You have chosen a specific GPU. This will completely '\n",
    "                      'disable data parallelism.')\n",
    "\n",
    "    return main_worker(args.gpu, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0122d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "val_cases = main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5b1d91",
   "metadata": {},
   "source": [
    "Check validation cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee56e4c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(val_cases)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5dd9d20",
   "metadata": {},
   "source": [
    "# Training Done\n",
    "\n",
    "## Run below to plot final predictions - hist and density plot and confusion matrix for binary classification only\n",
    "\n",
    "Load best model and evaluate on that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41debb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_best_model(args):\n",
    "    state_path = os.path.join(args.checkpoint, f'BaselineResNet{args.version}', 'model_best.pth.tar')\n",
    "    best_state = torch.load(state_path)\n",
    "    print('Best model at epoch: ', best_state['epoch'])\n",
    "    best_state_dict = best_state['state_dict']\n",
    "    \n",
    "    model = torchvision.models.resnet50(pretrained=True)\n",
    "    model.fc = nn.Linear(in_features=args.features, out_features=args.num_classes, bias=True)\n",
    "    model.load_state_dict(best_state_dict, strict=True)\n",
    "    \n",
    "    if not torch.cuda.is_available():\n",
    "        print('using CPU, this will be slow')\n",
    "    elif args.gpu is not None:\n",
    "        torch.cuda.set_device(args.gpu)\n",
    "        model = model.cuda(args.gpu)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec6e58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_data(args, val_cases):\n",
    "    patch_labels = pd.read_csv(args.patch_label, index_col=0)\n",
    "    patch_labels = patch_labels[patch_labels.magnification == args.magnification]\n",
    "    patch_labels = patch_labels.dropna(subset=[args.predicting_var])\n",
    "    patch_labels = select_cohort(patch_labels, args.cohort)\n",
    "\n",
    "    if val_cases is None:\n",
    "        cases = patch_labels.case.unique()\n",
    "        num_train_cases = int(np.ceil(len(cases) * args.train_val_split))\n",
    "        random.seed(args.seed)\n",
    "        random.shuffle(cases)\n",
    "        train_cases = cases[:num_train_cases]\n",
    "        val_cases = cases[num_train_cases:]\n",
    "        val_patch_labels = patch_labels[patch_labels.case.isin(val_cases)].reset_index(drop=True)\n",
    "    else:\n",
    "        val_patch_labels = patch_labels[patch_labels.case.isin(val_cases)].reset_index(drop=True)\n",
    "    return val_cases, val_patch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60add57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_slides(model, val_cases, args):\n",
    "    model.eval()\n",
    "    \n",
    "    outputs = []\n",
    "    targets = []\n",
    "    predictions = []\n",
    "    \n",
    "    val_cases, val_patch_labels = validation_data(args, val_cases)\n",
    "    \n",
    "    val_slides = val_patch_labels.slide.unique()\n",
    "    print(f'{len(val_slides)} slides')\n",
    "    \n",
    "    _, lim_transforms = image_transforms(args.random_crop)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        sig = nn.Sigmoid()\n",
    "        for j in range(len(val_slides)):\n",
    "            \n",
    "            slide = val_slides[j]\n",
    "            slide_patch_labels = val_patch_labels[val_patch_labels.slide==slide].reset_index(drop=True)\n",
    "            print(f'{slide} has {len(slide_patch_labels)} patches')\n",
    "            \n",
    "            val_dataset = PatchPathDataset(patch_labels=slide_patch_labels, image_folder=args.image_dir,\n",
    "                                           predicting_var=args.predicting_var, transform=lim_transforms)\n",
    "\n",
    "            val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=args.batch_size, shuffle=False,\n",
    "                                                     num_workers=args.workers, pin_memory=True, sampler=None)\n",
    "            patch_outputs = []\n",
    "            for i, (images, target, _) in enumerate(val_loader):\n",
    "                if args.gpu is not None:\n",
    "                    images = images.cuda(args.gpu, non_blocking=True)\n",
    "\n",
    "                output = model(images)\n",
    "                patch_outputs.extend(output)\n",
    "            \n",
    "            del val_dataset, val_loader\n",
    "            \n",
    "            patch_outputs = torch.stack(patch_outputs, dim=0)\n",
    "            slide_output = torch.mean(sig(patch_outputs))\n",
    "            slide_target = slide_patch_labels[args.predicting_var].iloc[0]\n",
    "            \n",
    "            outputs.append(slide_output.item())\n",
    "            targets.append(slide_target)\n",
    "            predictions.append(torch.round(slide_output).item())\n",
    "            \n",
    "    return targets, outputs, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecf77d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_result_figure(img_name, fig):\n",
    "    img_save_dir = os.path.join('Results/Figures', f'BaselineResNet{args.version}')\n",
    "    if not os.path.exists(img_save_dir):\n",
    "        os.makedirs(img_save_dir)\n",
    "    img_save_path = os.path.join(img_save_dir, img_name)\n",
    "    fig.savefig(img_save_path)\n",
    "    \n",
    "\n",
    "def plot_confusion_matrix(targets, predictions, label_names=['0', '1'], save=True):\n",
    "    cm = confusion_matrix(targets, predictions)\n",
    "    cm_df = pd.DataFrame(cm,\n",
    "                         index = label_names, \n",
    "                         columns = label_names)\n",
    "    plt.figure(figsize=(7,5))\n",
    "    g = sns.heatmap(cm_df, annot=True, fmt='g', cmap='Blues')\n",
    "    fig = g.get_figure()\n",
    "    # or fig = on the plt.figure()\n",
    "    plt.title(f'Confusion Matrix v{args.version}')\n",
    "    plt.ylabel('Actual Values')\n",
    "    plt.xlabel('Predicted Values')\n",
    "    \n",
    "    if save:\n",
    "        print('Saving figure')\n",
    "        save_result_figure('ValidationConfusionMatrix', fig)\n",
    "        if args.log:\n",
    "            val_summary_writer.add_figure('Validation Confusion Matrix', fig)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "# binary classification only \n",
    "def density_plot(targets, outputs, label_names=['0', '1'], save=True):\n",
    "    nocr_idx = [idx for idx, elt in enumerate(targets) if elt == 0]\n",
    "    nocr_probs = [outputs[idx] for idx in nocr_idx]\n",
    "    cr_idx = [idx for idx, elt in enumerate(targets) if elt == 1]\n",
    "    cr_probs = [outputs[idx] for idx in cr_idx]\n",
    "    \n",
    "    sns.set_style('whitegrid')\n",
    "    g = sns.kdeplot(nocr_probs, bw_adjust=0.5, label=label_names[0], c=list(colors.TABLEAU_COLORS.values())[0])\n",
    "    g = sns.kdeplot(cr_probs, bw_adjust=0.5, label=label_names[1], c=list(colors.TABLEAU_COLORS.values())[1])\n",
    "    g.set(xlim=(0, 1))\n",
    "    g.set_title('Density plot of predicted probabilties across true labels')\n",
    "    g.legend()\n",
    "    fig = g.get_figure()\n",
    "\n",
    "    if save:\n",
    "        print('Saving figure')\n",
    "        save_result_figure('ValidationDensityPlot', fig)\n",
    "        if args.log:\n",
    "            val_summary_writer.add_figure('Validation Density Plot', fig)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "def plot_prediction_scatter(targets, outputs, save=True):\n",
    "    fig = plt.figure(figsize=(6, 4))\n",
    "    plt.plot(targets, outputs, '.', alpha=1.0, color=list(colors.TABLEAU_COLORS.values())[0])\n",
    "    plt.xlabel(\"targets\")\n",
    "    plt.ylabel(\"predictions\")\n",
    "    plt.xlim([0,1])\n",
    "    plt.ylim([0,1])\n",
    "    plt.title(f'Predicted vs Target')\n",
    "    m, b = np.polyfit(x=targets, y=predictions, deg=1)\n",
    "    plt.plot(targets, m*np.array(list(map(float, targets))) + b, color=list(colors.TABLEAU_COLORS.values())[1],\n",
    "             alpha=0.6)\n",
    "    \n",
    "    if save:\n",
    "        print('Saving figure')\n",
    "        save_result_figure('ValidationScatterPlot', fig)\n",
    "        if args.log:\n",
    "            val_summary_writer.add_figure('Validation Scatter Plot', fig)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5891a66",
   "metadata": {},
   "source": [
    "### Generate predictions from best model epoch over validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6352dcde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(args):\n",
    "    best_model = load_best_model(args)\n",
    "    targets, outputs, predictions = validate_slides(best_model, val_cases, args)\n",
    "    \n",
    "    if args.prediction == 'binary classification':\n",
    "        if args.log:\n",
    "            plot_confusion_matrix(targets, predictions)\n",
    "            density_plot(targets, outputs)\n",
    "        \n",
    "        plot_confusion_matrix(targets, predictions, save=False)\n",
    "        density_plot(targets, outputs, save=False)\n",
    "    \n",
    "        # slide-level accuracy and AUC\n",
    "        slide_level_auc = roc_auc_score(targets, predictions, multi_class='ovr', average='weighted')\n",
    "        slide_level_acc = accuracy_score(predictions, targets)\n",
    "    \n",
    "        print('Validation AUC:', slide_level_auc)\n",
    "        print('Validation Accuracy:', slide_level_acc)\n",
    "        \n",
    "        if args.log:\n",
    "            val_summary_writer.add_scalar('Best/Slide-level AUC', slide_level_auc)\n",
    "            val_summary_writer.add_scalar('Best/Slide-level accuracy', slide_level_acc)\n",
    "    else:\n",
    "        print(f'Implement evaluation for {args.prediction}')\n",
    "    \n",
    "    val_summary_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093b6cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
