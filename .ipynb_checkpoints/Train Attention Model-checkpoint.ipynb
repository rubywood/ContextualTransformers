{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c9bdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import shutil\n",
    "import datetime\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from skimage.io import imread\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\n",
    "from scipy.stats import pearsonr\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "from utils.logging import *\n",
    "from data.datasets import PatchPathDataset\n",
    "from data.process import *\n",
    "\n",
    "import model.ViT as ViT\n",
    "import model.ClusterViT as ClusterViT\n",
    "import model.PREViT as PREViT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922a6ac3",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8229cf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = pd.Series({\n",
    "    'checkpoint':'checkpoint/',\n",
    "    'version': '1.0',\n",
    "    'image_dir': 'Data/',\n",
    "    'patch_label': 'Metadata/PatchLabels.csv',\n",
    "    'predicting_var': 'response',\n",
    "    'cohort': 'Cohort1',\n",
    "    'magnification': '10X',\n",
    "    'num_classes': 1,\n",
    "    'prediction': 'binary classification', # ['regression', 'binary classification', classification']\n",
    "    'att_model': 'ClusterPREViT',\n",
    "    'att_version': '1.0',\n",
    "    'base_epoch': 19,\n",
    "    'max_num_patches': 10000,\n",
    "    'normalize_clusters': True,\n",
    "    'n_clusters': 4,\n",
    "    'upsample': True,\n",
    "    'train_val_split': 0.7,\n",
    "    'random_crop': False,\n",
    "    'features': 2048,\n",
    "    'loss': 'bce',\n",
    "    'epochs': 20, \n",
    "    'start_epoch': 0,\n",
    "    'lr': 0.1,\n",
    "    'momentum': 0.9,\n",
    "    'weight_decay': 1e-4,\n",
    "    'batch_size': 256,\n",
    "    'workers': 4,\n",
    "    'evaluate': False,\n",
    "    'seed': 0,\n",
    "    'gpu': 0,\n",
    "    'log_interval': 50,\n",
    "    'log': False\n",
    "})\n",
    "\n",
    "\n",
    "if args.log:\n",
    "    tensorboard_dir = f'logs/tensorboard/BaselineResNet{args.version}/{args.att_model}{args.att_version}/' \n",
    "    if not os.path.exists(tensorboard_dir):\n",
    "        os.makedirs(tensorboard_dir)\n",
    "    \n",
    "    current_time = str(datetime.datetime.now().strftime(\"%d%m%Y-%H:%M:%S\"))\n",
    "    train_log_dir = tensorboard_dir + 'train/' + current_time\n",
    "    val_log_dir = tensorboard_dir + 'val/' + current_time\n",
    "    train_summary_writer = SummaryWriter(log_dir=train_log_dir)\n",
    "    val_summary_writer = SummaryWriter(log_dir=val_log_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8746ca94",
   "metadata": {},
   "source": [
    "### Functions to define metrics and save figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8bff0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_result_figure(img_name, fig):\n",
    "    img_save_dir = os.path.join('/well/rittscher/users/axs296/Code/FromScratch/Results/Figures', \n",
    "                                 f'BaselineResNet{args.version}/{args.att_model}{args.att_version}')\n",
    "    if not os.path.exists(img_save_dir):\n",
    "        os.makedirs(img_save_dir)\n",
    "    img_save_path = os.path.join(img_save_dir, img_name)\n",
    "    fig.savefig(img_save_path)\n",
    "\n",
    "    \n",
    "def save_checkpoint(state, is_best, epoch, args, filename='checkpoint.pth.tar'):\n",
    "    save_dir = os.path.join(args.checkpoint, f'BaselineResNet{args.version}', f'{args.att_model}{args.att_version}')\n",
    "    epoch_dir = os.path.join(save_dir, f'epoch_{epoch}')\n",
    "    if not os.path.exists(epoch_dir):\n",
    "        os.makedirs(epoch_dir)\n",
    "        print(f'Created new directory for saving models at {epoch_dir}')\n",
    "    save_path = os.path.join(epoch_dir, filename)\n",
    "    torch.save(state, save_path)\n",
    "    best_path = os.path.join(save_dir, 'model_best.pth.tar')\n",
    "    if is_best:\n",
    "        shutil.copyfile(save_path, best_path)\n",
    "\n",
    "\n",
    "def metrics(output, target):\n",
    "    with torch.no_grad():\n",
    "        sig = nn.Sigmoid()\n",
    "        if args.prediction == 'binary classification':\n",
    "            prob_output = sig(output)\n",
    "            first_acc = roc_auc_score(target.cpu(), prob_output.cpu(), multi_class='ovr', average='weighted')\n",
    "            second_acc = accuracy_score(torch.round(prob_output).cpu(), target.cpu())\n",
    "        elif args.prediction == 'classification':\n",
    "            first_acc = roc_auc_score(target.cpu(), output.cpu(), multi_class='ovo', average='macro')\n",
    "            second_acc = accuracy_score(torch.argmax(output).cpu(), target.cpu())\n",
    "        elif args.prediction == 'regression':\n",
    "            mae_loss = nn.L1Loss()\n",
    "            first_acc = mae_loss(output.squeeze(), target)\n",
    "            second_acc, _ = pearsonr(target.cpu(), output.squeeze().cpu())\n",
    "        else:\n",
    "            raise IOError(f'Metrics not defined for prediction format: {args.prediction}')\n",
    "        return first_acc, second_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04b98b6",
   "metadata": {},
   "source": [
    "### Functions to load features and clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265fa3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_slide_features(slide):\n",
    "    # slide should be slide name\n",
    "    feature_path = os.path.join(args.checkpoint, f'BaselineResNet{args.version}', 'Features', \n",
    "                                f'epoch_{args.base_epoch}')\n",
    "    if not os.path.exists(feature_path):\n",
    "        os.makedirs(feature_path)\n",
    "    slide_feature_path = os.path.join(feature_path, slide)\n",
    "    if os.path.exists(slide_feature_path):\n",
    "        slide_embeddings_paths = torch.load(slide_feature_path, map_location=torch.device('cuda'))\n",
    "    else:\n",
    "        print(f'WARNING: No features found for slide {slide} at {slide_feature_path}.' + \n",
    "              'Run \"Save ResNet Feature Embeddings\" notebook first.')\n",
    "    return slide_embeddings_paths\n",
    "\n",
    "def get_target(slide, patch_labels, gpu):\n",
    "    slide_patch_labels = patch_labels[patch_labels.slide==slide].reset_index(drop=True)\n",
    "    target = torch.FloatTensor([[slide_patch_labels[args.predicting_var].iloc[0]]])\n",
    "    if torch.cuda.is_available():\n",
    "        target = target.cuda(args.gpu, non_blocking=True)\n",
    "    return target\n",
    "\n",
    "def add_one_to_clusters(clusters):\n",
    "    for key, val in clusters.items():\n",
    "        clusters[key] = val + 1\n",
    "    return clusters\n",
    "\n",
    "def load_clusters(args, stage):\n",
    "    if args.normalize_clusters:\n",
    "        norm_str = 'normalized_'\n",
    "    else:\n",
    "        norm_str = ''\n",
    "    \n",
    "    cluster_path = os.path.join(args.checkpoint, f'BaselineResNet{args.version}', 'Clusters', \n",
    "                            f'epoch_{args.base_epoch}', stage)\n",
    "    assert os.path.exists(cluster_path)\n",
    "    \n",
    "    clusters = pickle.load(open(os.path.join(cluster_path, f'{args.n_clusters}_{norm_str}clusters.p'), 'rb')) \n",
    "    print('Loaded clusters.')\n",
    "\n",
    "    # add one to cluster labels\n",
    "    return add_one_to_clusters(clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0f9905",
   "metadata": {},
   "source": [
    "### Functions for predicting with attention model on slide level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81f1609",
   "metadata": {},
   "outputs": [],
   "source": [
    "def limit_input_size(slide_embeddings, clusters, patch_paths, max_num_patches):\n",
    "    if slide_embeddings.size()[0] > max_num_patches:\n",
    "        slide_cluster_path_embeddings = list(zip(slide_embeddings, clusters, patch_paths))\n",
    "        random.shuffle(slide_cluster_path_embeddings)\n",
    "        slide_cluster_path_embeddings = slide_cluster_path_embeddings[:(max_num_patches - 1)]\n",
    "        slide_embeddings, clusters, patch_paths = zip(*slide_cluster_path_embeddings)\n",
    "        slide_embeddings = torch.stack(slide_embeddings)\n",
    "        clusters = list(clusters)\n",
    "        patch_paths = list(patch_paths)\n",
    "        del slide_cluster_path_embeddings\n",
    "        print(f'Taking {max_num_patches - 1} random patches from slide {slide}' +\n",
    "              ' because image too large')\n",
    "    return slide_embeddings, clusters, patch_paths\n",
    "\n",
    "def predict(att_model, att_model_name, slide_embeddings, clusters=None, patch_paths=None):\n",
    "    if att_model_name == 'ViT':\n",
    "        output = att_model(slide_embeddings.unsqueeze(0))\n",
    "    elif att_model_name == 'PREViT':\n",
    "        output = att_model(slide_embeddings.unsqueeze(0), patch_paths)\n",
    "    elif att_model_name == 'ClusterViT':\n",
    "        output = att_model(slide_embeddings.unsqueeze(0), clusters)\n",
    "    if att_model_name == 'ClusterPREViT':\n",
    "        output = att_model(slide_embeddings.unsqueeze(0), clusters, patch_paths)\n",
    "    return output\n",
    "\n",
    "def num_patches_in_slide(slide, patch_labels):\n",
    "    return len(patch_labels[patch_labels.slide == slide])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9552fb",
   "metadata": {},
   "source": [
    "### Train and validate functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7230e5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_patch_labels, upsampled_train_slides, train_clusters, att_model, criterion, optimizer, \n",
    "          epoch, args, first_metric, second_metric, max_num_patches):\n",
    "\n",
    "    batch_time = AverageMeter('Time', ':4.3f')\n",
    "    data_time = AverageMeter('Data', ':4.3f')\n",
    "    losses = AverageMeter('Loss', ':4.2f')\n",
    "    metric = AverageMeter(first_metric, ':4.2f')\n",
    "    metric2 = AverageMeter(second_metric, ':4.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(upsampled_train_slides),\n",
    "        [batch_time, data_time, losses, metric, metric2],\n",
    "        prefix=\"Epoch: [{}]\".format(epoch),\n",
    "        summary_prefix='Training:')\n",
    "    \n",
    "    full_transforms, _ = image_transforms(args.random_crop)\n",
    "    \n",
    "    att_model.train()\n",
    "    end = time.time()\n",
    "        \n",
    "    outputs = []\n",
    "    targets = []\n",
    "\n",
    "    for i in range(len(upsampled_train_slides)):\n",
    "        data_time.update(time.time() - end)\n",
    "        \n",
    "        slide = upsampled_train_slides[i]\n",
    "\n",
    "        target = get_target(slide, train_patch_labels, args.gpu)\n",
    "        clusters = train_clusters[slide]\n",
    "\n",
    "        slide_embeddings_paths = load_slide_features(slide)\n",
    "        slide_embeddings = slide_embeddings_paths['slide_embeddings']\n",
    "        patch_paths = slide_embeddings_paths['patch_paths']\n",
    "        del slide_embeddings_paths\n",
    "        \n",
    "        slide_embeddings, clusters, patch_paths = limit_input_size(slide_embeddings, clusters, patch_paths, \n",
    "                                                                   max_num_patches)\n",
    "\n",
    "        output = predict(att_model, args.att_model, slide_embeddings, clusters=clusters, patch_paths=patch_paths)\n",
    "\n",
    "        loss = criterion(output, target)\n",
    "        losses.update(loss.item(), len(patch_paths))\n",
    "        \n",
    "        outputs.extend(output)\n",
    "        targets.extend(target)\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "    \n",
    "        if i % args.log_interval == 0:\n",
    "            progress.display(i)    \n",
    "        \n",
    "        del i, slide_embeddings, target, output\n",
    "        \n",
    "    outputs = torch.stack(outputs, dim=0)\n",
    "    targets = torch.stack(targets, dim=0)\n",
    "    \n",
    "    acc1, acc2 = metrics(outputs, targets, args.predicting_var)\n",
    "    metric.update(acc1, len(upsampled_train_slides))\n",
    "    metric2.update(acc2, len(upsampled_train_slides))\n",
    "    \n",
    "    del outputs, targets\n",
    "    \n",
    "    progress.display_summary()\n",
    "    \n",
    "    if args.log:\n",
    "        train_summary_writer.add_scalar(f'Loss/{args.loss}', losses.avg, epoch)\n",
    "        train_summary_writer.add_scalar(first_metric, metric.avg, epoch)\n",
    "        train_summary_writer.add_scalar(second_metric, metric2.avg, epoch)\n",
    "\n",
    "    \n",
    "def validate(val_patch_labels, val_clusters, att_model, criterion, epoch, args, first_metric, \n",
    "             second_metric, max_num_patches):\n",
    "    val_slides = val_patch_labels.slide.unique()\n",
    "\n",
    "    batch_time = AverageMeter('Time', ':4.3f', Summary.NONE)\n",
    "    losses = AverageMeter('Loss', ':4.2f', Summary.NONE)\n",
    "    metric1 = AverageMeter(first_metric, ':4.2f', Summary.AVERAGE)\n",
    "    metric2 = AverageMeter(second_metric, ':4.2f', Summary.AVERAGE)\n",
    "    progress = ProgressMeter(\n",
    "        len(val_slides),\n",
    "        [batch_time, losses, metric1, metric2],\n",
    "        prefix='Validation: ',\n",
    "        summary_prefix='Validation: ')\n",
    "\n",
    "    _, lim_transforms = image_transforms(args.random_crop)\n",
    "    \n",
    "    att_model.eval()\n",
    "    \n",
    "    end = time.time()\n",
    "\n",
    "    outputs = []\n",
    "    targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(val_slides)):            \n",
    "            slide = val_slides[i]\n",
    "            \n",
    "            target = get_target(slide, val_patch_labels, args.gpu)\n",
    "            clusters = val_clusters[slide]\n",
    "\n",
    "            slide_embeddings_paths = load_slide_features(slide)\n",
    "            slide_embeddings = slide_embeddings_paths['slide_embeddings']\n",
    "            patch_paths = slide_embeddings_paths['patch_paths']\n",
    "            del slide_embeddings_paths\n",
    "            \n",
    "            slide_embeddings, clusters, patch_paths = limit_input_size(slide_embeddings, clusters, patch_paths, \n",
    "                                                                   max_num_patches)\n",
    "        \n",
    "            output = predict(att_model, args.att_model, slide_embeddings, clusters=clusters, patch_paths=patch_paths)\n",
    "\n",
    "            loss = criterion(output, target)\n",
    "            losses.update(loss.item(), len(patch_paths))\n",
    "            \n",
    "            outputs.extend(output)\n",
    "            targets.extend(target)\n",
    "        \n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "        \n",
    "            if i % args.log_interval == 0:\n",
    "                progress.display(i)    \n",
    "            \n",
    "            del i, slide_embeddings, target, output\n",
    "        \n",
    "    outputs = torch.stack(outputs, dim=0)\n",
    "    targets = torch.stack(targets, dim=0)\n",
    "\n",
    "    acc1, acc2 = metrics(outputs, targets, args.predicting_var)\n",
    "    metric1.update(acc1, len(val_slides))\n",
    "    metric2.update(acc2, len(val_slides))\n",
    "    del outputs, targets\n",
    "    \n",
    "    progress.display_summary()\n",
    "    \n",
    "    if args.log:\n",
    "        val_summary_writer.add_scalar(f'Loss/{args.loss}', losses.avg, epoch)\n",
    "        val_summary_writer.add_scalar(first_metric, metric1.avg, epoch)\n",
    "        val_summary_writer.add_scalar(second_metric, metric2.avg, epoch)\n",
    "    \n",
    "    return metric1.avg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda971af",
   "metadata": {},
   "source": [
    "# Train Attention Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5d9ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_worker(gpu, args):\n",
    "    global best_acc1\n",
    "    args.gpu = gpu\n",
    "\n",
    "    if not torch.cuda.is_available():\n",
    "        print('using CPU, this will be slow')\n",
    "    elif args.gpu is not None:\n",
    "        print(\"Use GPU: {} for training\".format(args.gpu))\n",
    "        torch.cuda.set_device(args.gpu)\n",
    "\n",
    "    if args.prediction in ['classification', 'binary classification']:\n",
    "        metric = 'AUC'\n",
    "        second_metric = 'Accuracy'\n",
    "    elif args.prediction == 'regression':\n",
    "        metric = 'Pearson correlation'\n",
    "        second_metric = 'MAE'\n",
    "    else:\n",
    "        raise IOError(f'Metrics not defined for prediction format: {args.prediction}')\n",
    "    \n",
    "    # Load data\n",
    "    patch_labels = pd.read_csv(args.patch_label, index_col=0)\n",
    "    patch_labels = patch_labels[patch_labels.magnification == args.magnification]\n",
    "    # drop NAs in column trying to predict\n",
    "    patch_labels = patch_labels.dropna(subset=[args.predicting_var])\n",
    "\n",
    "    train_patch_labels, val_patch_labels, val_cases, upsampled_train_slides = split_train_val(patch_labels, \n",
    "                                                                                              args.cohort, \n",
    "                                                                                              args.train_val_split,\n",
    "                                                                                              args.seed, \n",
    "                                                                                              args.prediction,\n",
    "                                                                                              args.predicting_var,\n",
    "                                                                                              args.upsample)    \n",
    "\n",
    "    # check saved_val_cases from baseline model are same as val_cases for attention model\n",
    "    assert (val_cases == saved_val_cases).all()\n",
    "    \n",
    "    train_slides = train_patch_labels.slide.unique()\n",
    "    print(f'{len(train_slides)} training slides')\n",
    "    val_slides = val_patch_labels.slide.unique()\n",
    "    print(f'{len(val_slides)} validation slides')\n",
    "\n",
    "    patch_distn = [num_patches_in_slide(slide, patch_labels) for slide in patch_labels.slide.unique()]\n",
    "    print(f'Max number of patches over all slides in dataset is {max(patch_distn)}')\n",
    "    max_num_patches = max(patch_distn)\n",
    "    if args.max_num_patches < max_num_patches:\n",
    "        max_num_patches = args.max_num_patches\n",
    "        print(f'Setting max number of patches to {max_num_patches}')\n",
    "    \n",
    "    train_clusters = load_clusters(args, 'Train')\n",
    "    val_clusters = load_clusters(args, 'Validation')\n",
    "    \n",
    "    # Define attention model\n",
    "    if args.att_model == 'ViT':    \n",
    "        att_model = ViT.ViT(num_classes=args.num_classes, dim=512, patch_dim=args.features, depth=4, heads=4, \n",
    "                            mlp_dim=512, max_num_patches=max_num_patches, pool='cls', dim_head=64, dropout=0.3,\n",
    "                            emb_dropout=0.3)\n",
    "    elif args.att_model == 'PREViT':\n",
    "        att_model = PREViT.PREViT(num_classes=args.num_classes, dim=512, depth=4, heads=4, mlp_dim=512, \n",
    "                                  patch_dim=args.features, pool='cls', dim_head=64, dropout=0.3, emb_dropout=0.3)\n",
    "    elif args.att_model == 'ClusterViT':\n",
    "        att_model = ClusterViT.ClusterViT(num_classes=args.num_classes, dim=512, depth=4, heads=4, mlp_dim=512, \n",
    "                                          patch_dim=args.features, max_num_patches=max_num_patches,\n",
    "                                          n_clusters=args.n_clusters, pool='cls', dim_head=64, dropout=0.3, \n",
    "                                          emb_dropout=0.3)\n",
    "    elif args.att_model == 'ClusterPREViT':\n",
    "        att_model = PREViT.ClusterPREViT(num_classes=args.num_classes, dim=512, depth=4, heads=4, mlp_dim=512, \n",
    "                                         patch_dim=args.features, n_clusters=args.n_clusters, pool='cls', \n",
    "                                         dim_head=64, dropout=0.3, emb_dropout=0.3)\n",
    "    else:\n",
    "        raise IOException(f\"No model defined for {args.att_model}\")\n",
    "    att_model = att_model.cuda(args.gpu)\n",
    "    \n",
    "    # define loss function (criterion), optimizer, and learning rate scheduler\n",
    "    if args.loss == 'ce':  # use in classification\n",
    "        criterion = nn.CrossEntropyLoss().cuda(args.gpu)\n",
    "    elif args.loss == 'mse':  # use in cts case (on either normalized or standardized or raw data)\n",
    "        criterion = nn.MSELoss().cuda(args.gpu)\n",
    "    elif args.loss == 'bce':  # use in binary case\n",
    "        criterion = nn.BCELoss().cuda(args.gpu)  # bce without sigmoid as already have sigmoid in ViT\n",
    "\n",
    "    optimizer = torch.optim.SGD(att_model.parameters(), args.lr,\n",
    "                                momentum=args.momentum,\n",
    "                                weight_decay=args.weight_decay)\n",
    "    \n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    scheduler = StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "\n",
    "    cudnn.benchmark = True\n",
    "    \n",
    "    if args.evaluate:\n",
    "        validate(val_patch_labels, val_clusters, att_model, criterion, epoch, args, metric, second_metric, \n",
    "                 max_num_patches)\n",
    "        return\n",
    "    \n",
    "    best_epoch = -1\n",
    "    for epoch in range(args.start_epoch, args.epochs):\n",
    "\n",
    "        # train for one epoch\n",
    "        random.shuffle(upsampled_train_slides)\n",
    "        train(train_patch_labels, upsampled_train_slides, train_clusters, att_model, criterion, \n",
    "              optimizer, epoch, args, metric, second_metric, max_num_patches)\n",
    "\n",
    "        # evaluate on validation set\n",
    "        acc1 = validate(val_patch_labels, val_clusters, att_model, criterion, epoch, args, metric, \n",
    "                        second_metric, max_num_patches)\n",
    "\n",
    "        scheduler.step()\n",
    "        \n",
    "        # remember best acc@1 and save checkpoint\n",
    "        if metric == 'AUC' or 'Pearson correlation':\n",
    "            is_best = acc1 > best_acc1\n",
    "            best_acc1 = max(acc1, best_acc1)\n",
    "        elif metric == 'MAE':\n",
    "            is_best = acc1 < best_acc1\n",
    "            best_acc1 = min(acc1, best_acc1)\n",
    "        else:\n",
    "            raise IOError(f'best metric scenario not defined for metric {metric}')\n",
    "        \n",
    "        if is_best:\n",
    "            best_epoch = epoch\n",
    "        \n",
    "        save_checkpoint({\n",
    "            'epoch': epoch,\n",
    "            'arch': args.att_model,\n",
    "            'state_dict': att_model.state_dict(),\n",
    "            'best_metric': best_acc1,\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'scheduler': scheduler.state_dict()\n",
    "        }, is_best, epoch, args)\n",
    "    \n",
    "    if args.log:\n",
    "        metric_dict = {f'Best/{metric}': best_acc1, 'Best/Epoch': best_epoch}\n",
    "        val_summary_writer.add_hparams(hparam_dict=args.to_dict(), metric_dict=metric_dict)\n",
    "    \n",
    "        train_summary_writer.close()\n",
    "        #val_summary_writer.close()\n",
    "    \n",
    "    del att_model\n",
    "    return val_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99877f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc1 = 0\n",
    "\n",
    "def main():\n",
    "    #args = parser.parse_args()\n",
    "\n",
    "    if args.seed is not None:\n",
    "        random.seed(args.seed)\n",
    "        torch.manual_seed(args.seed)\n",
    "        cudnn.deterministic = True\n",
    "        warnings.warn('You have chosen to seed training. '\n",
    "                      'This will turn on the CUDNN deterministic setting, '\n",
    "                      'which can slow down your training considerably! '\n",
    "                      'You may see unexpected behavior when restarting '\n",
    "                      'from checkpoints.')\n",
    "\n",
    "    if args.gpu is not None:\n",
    "        warnings.warn('You have chosen a specific GPU. This will completely '\n",
    "                      'disable data parallelism.')\n",
    "\n",
    "    return main_worker(args.gpu, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f04d31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "val_cases = main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142aafe7",
   "metadata": {},
   "source": [
    "# Training done\n",
    "\n",
    "### Evaluate model by generating predictions from best epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59497d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_best_model(args):\n",
    "    state_path = os.path.join(args.checkpoint, f'BaselineResNet{args.version}', f'{args.att_model}{args.att_version}',\n",
    "                              'model_best.pth.tar')\n",
    "    best_state = torch.load(state_path)\n",
    "    print('Best model at epoch: ', best_state['epoch'])\n",
    "    best_state_dict = best_state['state_dict']\n",
    "    \n",
    "    if args.att_model == 'ViT':    \n",
    "        att_model = ViT.ViT(num_classes=args.num_classes, dim=512, patch_dim=args.features, depth=4, heads=4, \n",
    "                            mlp_dim=512, max_num_patches=max_num_patches, pool='cls', dim_head=64, dropout=0.3,\n",
    "                            emb_dropout=0.3)\n",
    "    elif args.att_model == 'PREViT':\n",
    "        att_model = PREViT.PREViT(num_classes=args.num_classes, dim=512, depth=4, heads=4, mlp_dim=512, \n",
    "                                  patch_dim=args.features, pool='cls', dim_head=64, dropout=0.3, emb_dropout=0.3)\n",
    "    elif args.att_model == 'ClusterViT':\n",
    "        att_model = ClusterViT.ClusterViT(num_classes=args.num_classes, dim=512, depth=4, heads=4, mlp_dim=512, \n",
    "                                          patch_dim=args.features, max_num_patches=max_num_patches,\n",
    "                                          n_clusters=args.n_clusters, pool='cls', dim_head=64, dropout=0.3, \n",
    "                                          emb_dropout=0.3)\n",
    "    elif args.att_model == 'ClusterPREViT':\n",
    "        att_model = PREViT.ClusterPREViT(num_classes=args.num_classes, dim=512, depth=4, heads=4, mlp_dim=512, \n",
    "                                         patch_dim=args.features, n_clusters=args.n_clusters, pool='cls', \n",
    "                                         dim_head=64, dropout=0.3, emb_dropout=0.3)\n",
    "    else:\n",
    "        raise IOException(f\"No model defined for {args.att_model}\")\n",
    "    att_model.load_state_dict(best_state_dict, strict=True)\n",
    "    \n",
    "    if not torch.cuda.is_available():\n",
    "        print('using CPU, this will be slow')\n",
    "    elif args.gpu is not None:\n",
    "        torch.cuda.set_device(args.gpu)\n",
    "        att_model = att_model.cuda(args.gpu)\n",
    "    \n",
    "    return att_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b150268",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_data(args, val_cases):\n",
    "    patch_labels = pd.read_csv(args.patch_label, index_col=0)\n",
    "    patch_labels = patch_labels[patch_labels.magnification == args.magnification]\n",
    "    patch_labels = patch_labels.dropna(subset=[args.predicting_var])\n",
    "    patch_labels = select_cohort(patch_labels, args.cohort)\n",
    "    \n",
    "    val_clusters = load_clusters(args, 'Validation')\n",
    "\n",
    "    if val_cases is None:\n",
    "        cases = patch_labels.case.unique()\n",
    "        num_train_cases = int(np.ceil(len(cases) * args.train_val_split))\n",
    "        random.seed(args.seed)\n",
    "        random.shuffle(cases)\n",
    "        train_cases = cases[:num_train_cases]\n",
    "        val_cases = cases[num_train_cases:]\n",
    "        val_patch_labels = patch_labels[patch_labels.case.isin(val_cases)].reset_index(drop=True)\n",
    "    else:\n",
    "        val_patch_labels = patch_labels[patch_labels.case.isin(val_cases)].reset_index(drop=True)\n",
    "    return val_cases, val_patch_labels, val_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc9fab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_slides(model, val_cases, max_num_patches, args):\n",
    "    torch.manual_seed(args.seed)\n",
    "    cudnn.deterministic = True\n",
    "    model.eval()\n",
    "    \n",
    "    outputs = []\n",
    "    targets = []\n",
    "    predictions = []\n",
    "    \n",
    "    val_cases, val_patch_labels, val_clusters = validation_data(args, val_cases)\n",
    "    val_slides = val_patch_labels.slide.unique()\n",
    "    print(f'{len(val_slides)} slides')\n",
    "\n",
    "    _, lim_transforms = image_transforms(args.random_crop)\n",
    "    \n",
    "    slides = []\n",
    "    with torch.no_grad():\n",
    "        for slide in val_slides:\n",
    "            slide_patch_labels = val_patch_labels[val_patch_labels.slide==slide].reset_index(drop=True)\n",
    "            print(f'{slide} has {len(slide_patch_labels)} patches')\n",
    "            clusters = val_clusters[slide]\n",
    "\n",
    "            slide_embeddings_paths = load_slide_features(slide)\n",
    "            slide_embeddings = slide_embeddings_paths['slide_embeddings']\n",
    "            patch_paths = slide_embeddings_paths['patch_paths']\n",
    "            del slide_embeddings_paths\n",
    "            \n",
    "            slide_embeddings, clusters, patch_paths = limit_input_size(slide_embeddings, clusters, patch_paths, \n",
    "                                                                       max_num_patches)\n",
    "            output = predict(model, args.att_model, slide_embeddings, clusters=clusters, patch_paths=patch_paths)\n",
    "                        \n",
    "            slide_target = slide_patch_labels[args.predicting_var].iloc[0]\n",
    "\n",
    "            outputs.append(output.item())\n",
    "            predictions.append(torch.round(output).item())\n",
    "            targets.append(slide_target)\n",
    "            slides.append(slide)\n",
    "            \n",
    "    return targets, outputs, predictions, slides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439228b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(targets, predictions, label_names=['0', '1'], save=True):\n",
    "    cm = confusion_matrix(targets, predictions)\n",
    "    cm_df = pd.DataFrame(cm,\n",
    "                         index = label_names, \n",
    "                         columns = label_names)\n",
    "    plt.figure(figsize=(7,5))\n",
    "    g = sns.heatmap(cm_df, annot=True, fmt='g', cmap='Blues')\n",
    "    fig = g.get_figure()\n",
    "    # or fig = on the plt.figure()\n",
    "    plt.title(f'Confusion Matrix v{args.version}')\n",
    "    plt.ylabel('Actual Values')\n",
    "    plt.xlabel('Predicted Values')\n",
    "    \n",
    "    if save:\n",
    "        print('Saving figure')\n",
    "        save_result_figure('ValidationConfusionMatrix', fig)\n",
    "        if args.log:\n",
    "            val_summary_writer.add_figure('Validation Confusion Matrix', fig)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "# binary classification only \n",
    "def density_plot(targets, outputs, label_names=['0', '1'], save=True):\n",
    "    nocr_idx = [idx for idx, elt in enumerate(targets) if elt == 0]\n",
    "    nocr_probs = [outputs[idx] for idx in nocr_idx]\n",
    "    cr_idx = [idx for idx, elt in enumerate(targets) if elt == 1]\n",
    "    cr_probs = [outputs[idx] for idx in cr_idx]\n",
    "    \n",
    "    sns.set_style('whitegrid')\n",
    "    g = sns.kdeplot(nocr_probs, bw_adjust=0.5, label=label_names[0], c=list(colors.TABLEAU_COLORS.values())[0])\n",
    "    g = sns.kdeplot(cr_probs, bw_adjust=0.5, label=label_names[1], c=list(colors.TABLEAU_COLORS.values())[1])\n",
    "    g.set(xlim=(0, 1))\n",
    "    g.set_title('Density plot of predicted probabilties across true labels')\n",
    "    g.legend()\n",
    "    fig = g.get_figure()\n",
    "    if save:\n",
    "        print('Saving figure')\n",
    "        save_result_figure('ValidationDensityPlot', fig)\n",
    "        if args.log:\n",
    "            val_summary_writer.add_figure('Validation Density Plot', fig)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "def plot_prediction_scatter(targets, outputs, save=True):\n",
    "    fig = plt.figure(figsize=(6, 4))\n",
    "    plt.plot(targets, outputs, '.', alpha=1.0, color=list(colors.TABLEAU_COLORS.values())[0])\n",
    "    plt.xlabel(\"targets\")\n",
    "    plt.ylabel(\"predictions\")\n",
    "    plt.xlim([0,1])\n",
    "    plt.ylim([0,1])\n",
    "    plt.title(f'Predicted vs Target')\n",
    "    m, b = np.polyfit(x=targets, y=predictions, deg=1)\n",
    "    plt.plot(targets, m*np.array(list(map(float, targets))) + b, color=list(colors.TABLEAU_COLORS.values())[1],\n",
    "             alpha=0.6)\n",
    "    \n",
    "    if save:\n",
    "        print('Saving figure')\n",
    "        save_result_figure('ValidationScatterPlot', fig)\n",
    "        if args.log:\n",
    "            val_summary_writer.add_figure('Validation Scatter Plot', fig)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d16b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(args):\n",
    "    best_model = load_best_model(args)\n",
    "    targets, outputs, predictions, slides = validate_slides(best_model, val_cases=None, \n",
    "                                                            max_num_patches=args.max_num_patches, args=args)\n",
    "    \n",
    "    if args.prediction == 'binary classification':\n",
    "        if args.log:\n",
    "            plot_confusion_matrix(targets, predictions)\n",
    "            density_plot(targets, outputs)\n",
    "        \n",
    "        plot_confusion_matrix(targets, predictions, save=False)\n",
    "        density_plot(targets, outputs, save=False)\n",
    "    \n",
    "        # slide-level accuracy and AUC\n",
    "        auc = roc_auc_score(targets, outputs, average='weighted')\n",
    "        acc = accuracy_score(targets, predictions)\n",
    "        weighted_acc = balanced_accuracy_score(targets, predictions)\n",
    "        f1 = f1_score(targets, predictions, average='weighted')\n",
    "        precision = precision_score(targets, predictions, average='weighted')\n",
    "        recall = recall_score(targets, predictions, average='weighted')\n",
    "        \n",
    "        print(f'{args.version}:')\n",
    "        print('- AUC', auc)\n",
    "        print('- Accuracy', acc)\n",
    "        print('- Balanced accuracy', weighted_acc)\n",
    "        print('- F1 score', f1)\n",
    "        print('- Precision', precision)\n",
    "        print('- Recall', recall)\n",
    "        \n",
    "        if args.log:\n",
    "            val_summary_writer.add_scalar('Best/Slide-level AUC', auc)\n",
    "            val_summary_writer.add_scalar('Best/Slide-level accuracy', acc)\n",
    "    else:\n",
    "        print(f'Implement evaluation for {args.prediction}')\n",
    "    \n",
    "    val_summary_writer.close()\n",
    "    \n",
    "    return targets, outputs, predictions, slides, auc, acc, weighted_acc, f1, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8b411a",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets, outputs, predictions, slides, auc, acc, weighted_acc, f1, precision, recall = evaluate(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ddd6835",
   "metadata": {},
   "source": [
    "### Save metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e5f90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pd.DataFrame(data=[(auc, acc, weighted_acc, f1, precision, recall)], \n",
    "                       index=[f'round_{args.seed}'], \n",
    "                       columns=['AUC', 'Accuracy', 'Balanced accuracy', 'F1', 'Precision', 'Recall'])\n",
    "\n",
    "mets_save_dir = os.path.join('Results/Metrics', f'{args.att_model}', \n",
    "                             f'BaselineResNet{args.version}_{args.att_model}{args.att_version}')\n",
    "if not os.path.exists(mets_save_dir):\n",
    "    os.makedirs(mets_save_dir)\n",
    "\n",
    "metrics.to_csv(os.path.join(mets_save_dir, f'round_{args.seed}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c54f22",
   "metadata": {},
   "source": [
    "### Save predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad75d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(data=list(zip(targets, outputs, predictions)), \n",
    "                       index=slides, columns=[f'Round{args.seed}_Target', f'Round{args.seed}_Output', \n",
    "                                              f'Round{args.seed}_Prediction'])\n",
    "\n",
    "preds_save_dir = os.path.join('Results/Predictions', \n",
    "                              f'BaselineResNet{args.version}_ClusterPREViT{args.att_model}')\n",
    "if not os.path.exists(preds_save_dir):\n",
    "    os.makedirs(preds_save_dir)\n",
    "    \n",
    "results.to_csv(os.path.join(preds_save_dir, f'round_{args.seed}'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
